import os
import json
import sys
import datetime

import numpy as np
import seaborn_image as isns
import matplotlib.pyplot as plt

sys.path.append("../../util")
import config_file
import pff
import image_quantiles

class ObservingRunFileInterface:

    def __init__(self, data_dir, run_dir):
        """File manager interface for a single observing run."""

        # Check data paths
        self.data_dir = data_dir
        self.run_dir = run_dir
        self.run_path = f'{self.data_dir}/{self.run_dir}'
        self.check_paths()

        # Unpack relevant data_config attributes
        self.data_config = config_file.get_data_config(self.run_path)
        self.run_type = self.data_config["run_type"]
        self.has_imaging_data = False
        if "image" in self.data_config:
            self.has_imaging_data = True
            self.intgrn_usec = float(self.data_config["image"]["integration_time_usec"]) * 1e-6
            self.img_bpp = int(self.data_config["image"]["quabo_sample_size"]) // 8  # Bytes per imaging pixel
            self.img_size = self.img_bpp * 32 ** 2
            self.frame_size = None
        self.has_pulse_height = False
        if "pulse_height" in self.data_config:
            self.has_pulse_height = True
            # TODO

        # Create a dict of all valid imaging pff files available for analysis, indexed by module.
        self.obs_config = config_file.get_obs_config(self.run_path)
        self.obs_pff_files = dict()
        for dome in self.obs_config["domes"]:
            for module in dome["modules"]:
                module_id = config_file.ip_addr_to_module_id(module["ip_addr"])
                self.obs_pff_files[module_id] = []
        if self.has_imaging_data:
            self.check_imaging_files()
            self.get_module_imaging_files()

    @staticmethod
    def get_next_frame(f, step_size, frame_size, bytes_per_pixel):
        """Returns the next image frame and json header from f."""
        j, img = None, None
        json_str = pff.read_json(f)
        if json_str is not None:
            j = json.loads(json_str)
            img = pff.read_image(f, 32, bytes_per_pixel)
            img = np.array(img)
            f.seek((step_size - 1) * frame_size, os.SEEK_CUR)  # Skip (step_size - 1) images
        return j, img

    @staticmethod
    def plot_image(img):
        if img is None or not isinstance(img, np.ndarray):
            print('no image')
            return None
        if img.shape != (32,32):
            img = np.reshape(img, (32, 32))
        mean = np.mean(img)
        std = np.std(img)
        # ax = isns.imghist(img, cmap="viridis", vmin=50, vmax=250)#vmin=max(0, mean - 2.5 * std), vmax=mean + 2.5 * std)
        ax = isns.imghist(img, cmap="viridis", vmin=-3.5, vmax=3.5)#vmin=max(0, mean - 2.5 * std), vmax=mean + 2.5 * std)
        return ax

    @staticmethod
    def plot_image_fft(img):
        if img is None or not isinstance(img, np.ndarray):
            print('no image')
            return None
        if img.shape != (32, 32):
            img = np.reshape(img, (32, 32))
        ax = isns.fftplot(img, cmap="viridis", window_type='cosine')
        return ax.get_figure()

    @staticmethod
    def get_tz_timestamp_str(unix_t, tz_hr_offset=0):
        """Returns the timestamp string, offset from utc by tz_hr_offset hours."""
        dt = datetime.datetime.fromtimestamp(unix_t, datetime.timezone(datetime.timedelta(hours=tz_hr_offset)))
        return dt.strftime("%m/%d/%Y, %H:%M:%S")


    def check_paths(self):
        """Check if data_dir and run_dir exist."""
        if not os.path.exists(self.data_dir):
            raise FileNotFoundError(f"The data_directory '{self.data_dir}' does not exist!")
        elif not os.path.exists(self.run_path):
            raise FileNotFoundError(f"The run directory at '{self.run_path}' does not exist!")

    def check_imaging_files(self):
        for fname in os.listdir(self.run_path):
            fpath = f'{self.run_path}/{fname}'
            if not (pff.is_pff_file(fname)
                    and pff.pff_file_type(fname) in ['img16', 'img8']
                    and os.path.getsize(fpath) > 0):
                continue
            parsed_name = pff.parse_name(fname)
            module_id = int(parsed_name["module"])
            if module_id not in self.obs_pff_files:
                raise FileExistsError(f'{fpath} was not generated by a module specified in obs_config.\n'
                                      f'This file may have been moved to {self.run_dir} from a different run.')
            if int(parsed_name["bpp"]) != self.img_bpp:
                raise FileExistsError(f'The bytes per pixel of {fpath} do not match the value specified in data_config.\n'
                                      f'This file may have been moved to {self.run_dir} from a different run.')

    def get_module_imaging_files(self):
        """Returns an array of dictionaries storing info for all available pff files for module_id."""
        for fname in os.listdir(self.run_path):
            fpath = f'{self.run_path}/{fname}'
            if not (pff.is_pff_file(fname)
                    and pff.pff_file_type(fname) in ['img16', 'img8']
                    and os.path.getsize(fpath) > 0):
                continue
            parsed_name = pff.parse_name(fname)
            module_id = int(parsed_name["module"])
            attrs = dict()
            attrs["fname"] = fname
            attrs["seqno"] = int(parsed_name["seqno"])
            with open(fpath, 'rb') as f:
                self.frame_size, attrs["nframes"], attrs["first_unix_t"], \
                    attrs["last_unix_t"] = pff.img_info(f, self.img_size)
            self.obs_pff_files[module_id] += [attrs]
        # Sort files_to_process in ascending order by file sequence number
        for module_id in self.obs_pff_files:
            self.obs_pff_files[module_id].sort(key=lambda attrs: attrs["seqno"])


    def frame_iterator(self, fp, step_size):
        return FrameIterator(fp, step_size, self.frame_size, self.img_bpp)



class FrameIterator:
    def __init__(self, fp, step_size, frame_size, bytes_per_pixel):
        """From the PFF file pointer fp, returns the image frame
        and json header step_size later than the previous image.
        Note that frames are NOT necessarily in chronological order"""
        self.fp = fp
        self.frame_size = frame_size
        self.bpp = bytes_per_pixel
        self.step_size = step_size

    def __iter__(self):
        return self

    def __next__(self):
        j, img = ObservingRunFileInterface.get_next_frame(self.fp, self.step_size, self.frame_size, self.bpp)
        if img is None:
            raise StopIteration
        return j, img

class ModuleImageInterface(ObservingRunFileInterface):

    def __init__(self, data_dir, run_dir, module_id, require_data=False):
        """Interface for doing analysis work with images produced by the specified module
        during the given observing run."""
        super().__init__(data_dir, run_dir)
        self.module_id = module_id
        if module_id not in self.obs_pff_files:
            raise ValueError(f"Module {module_id} did not exist for the run '{run_dir}'.")
        self.module_pff_files = self.obs_pff_files[module_id]

        # Check if there are any images for this module.
        if len(self.module_pff_files) == 0:
            msg = f"No valid panoseti imaging data for module {module_id} in '{self.run_dir}'."
            if require_data:
                raise FileNotFoundError(msg)
            else:
                print(msg)
                self.start_unix_t = None
        else:
            self.start_unix_t = self.module_pff_files[0]['first_unix_t']


class PanosetiBatchBuilder(ObservingRunFileInterface):
    def __init__(self, data_dir, run_dir, task, batch_id):
        super().__init__(data_dir, run_dir)
        self.task = task
        self.batch_id = batch_id

        self.batch_dir = ...

    def get_panoseti_batch_dir(self):
        ...

    def gen_npy_fname(self):
        npy_fname = f"{self.batch_dir}/data.npy"
        return npy_fname


    def get_empty_data_array(self, file_attrs, step_size):
        data_size = 0
        for i in range(len(file_attrs)):
            data_size += file_attrs[i]['nframes'] // step_size
        return np.zeros(data_size)

    def get_files_to_process(self, data_dir, run_dir, module):
        files_to_process = []
        for fname in os.listdir(f'{data_dir}/{run_dir}'):
            if pff.is_pff_file(fname) and pff.pff_file_type(fname) in ('img16', 'img8'):
                files_to_process.append(fname)
        return files_to_process

    def process_file(self, file_info, data, itr_info, step_size):
        """On a sample of the frames in the file represented by file_info, add the total
        image brightness to the data array beginning at data_offset."""
        with open(f"{self.data_dir}/{self.run_dir}/{file_info['fname']}", 'rb') as f:
            # Start file pointer with an offset based on the previous file -> ensures even frame sampling
            f.seek(
                itr_info['fstart_offset'] * file_info['frame_size'],
                os.SEEK_CUR
            )
            new_nframes = file_info['nframes'] - itr_info['fstart_offset']
            for i in range(new_nframes // step_size):
                j, img = self.get_next_frame(f, file_info['frame_size'], file_info['bytes_per_pixel'], step_size)
                data[itr_info['data_offset'] + i] = np.sum(img)
            itr_info['fstart_offset'] = file_info['nframes'] - (new_nframes // step_size) * step_size


    def get_data(self, file_info_array, analysis_dir, step_size):
        # Save reduced data to file
        npy_fname = self.gen_npy_fname(analysis_dir)
        if os.path.exists(npy_fname):
            data_arr = np.load(npy_fname)
            return data_arr
        itr_info = {
            "data_offset": 0,
            "fstart_offset": 0  # Ensures frame step size across files
        }
        data_arr = self.get_empty_data_array(file_info_array, step_size)
        for i in range(len(file_info_array)):
            print(f"Processing {file_info_array[i]['fname']}")
            file_info = file_info_array[i]
            self.process_file(file_info, data_arr, itr_info, step_size)
            itr_info['data_offset'] += file_info["nframes"] // step_size

        np.save(npy_fname, data_arr)
        return data_arr


if __name__ == '__main__':
    DATA_DIR = '/Users/nico/Downloads/panoseti_test_data/obs_data/data'
    # RUN_DIR = 'obs_Lick.start_2023-08-29T04:49:58Z.runtype_sci-obs.pffd'
    RUN_DIR = 'obs_Lick.start_2023-08-01T05:14:21Z.runtype_sci-obs.pffd'

    test_batch_builder = PanosetiBatchBuilder(DATA_DIR, RUN_DIR, 'cloud-detection', 0)
    test_mii = ModuleImageInterface(DATA_DIR, RUN_DIR, 254)
    print(test_mii.module_pff_files[0]['nframes'])
    for i in range(0, len(test_mii.module_pff_files)):
        print(f"Plotting {test_mii.module_pff_files[i]['fname']}")
        fpath = test_mii.run_path + '/' + test_mii.module_pff_files[i]['fname']
        with open(fpath, 'rb') as fp:
            fig = None
            from collections import deque
            maxlen = 30
            hist = []#deque(maxlen=maxlen)
            for j, img in test_mii.frame_iterator(fp, 10000):
                if fig:
                    plt.close(fig)
                if len(hist) == maxlen:
                    mean = np.mean(hist)
                    std = np.std(hist)
                    prev_img = hist.pop(0)#popleft()
                    diff = (img -prev_img) / std
                    # diff=img
                    # diff[diff < 0] = 0
                    fig = test_mii.plot_image(diff)
                plt.pause(.1)
                hist.append(img)
            plt.close(fig)

